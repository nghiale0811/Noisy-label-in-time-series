{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dietary-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from hmmlearn import hmm\n",
    "from torch.distributions import uniform\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "dedicated-deviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Datasets using HMM\n",
    "\n",
    "def random_transmat(n_states):\n",
    "    matrix = np.random.rand(n_states, n_states)\n",
    "    return matrix/matrix.sum(axis=1)[:,None]\n",
    "\n",
    "def random_startprob(n_states):\n",
    "    startprob = np.random.rand(n_states)\n",
    "    return startprob/startprob.sum()\n",
    "\n",
    "def generate_hmm(n_states, n_samples, length):\n",
    "    #GENERATING A MODEL\n",
    "    model = hmm.GaussianHMM(n_components=n_states, covariance_type=\"full\")\n",
    "    model.startprob_ = random_startprob(n_states)\n",
    "    model.transmat_ = random_transmat(n_states)\n",
    "\n",
    "    model.means_ = np.array([[0.0, 0.0], \n",
    "                             [5.0, 10.0],\n",
    "                            [5.0, 10.0]])\n",
    "    model.covars_ = np.tile(np.identity(2), (3, 1, 1))\n",
    "\n",
    "\n",
    "    #SAMPLING FROM MODEL and STORING IN TENSOR\n",
    "\n",
    "    #Number of Samples in Dataset\n",
    "    dataset=[]\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        X, Z = model.sample(length)\n",
    "        X = np.reshape(X[:,0],(length,1))\n",
    "        dataset.append(torch.Tensor(X))\n",
    "\n",
    "    dataset = torch.stack(dataset)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def generate_time_dependent_flip(n_samples, length, startprob, transmat):\n",
    "    #GENERATING A MODEL\n",
    "\n",
    "\n",
    "    model = hmm.GaussianHMM(n_components=n_states, covariance_type=\"full\")\n",
    "    model.startprob_ = startprob\n",
    "    model.transmat_ = transmat\n",
    "\n",
    "    #this doesn't actually matter for us\n",
    "    model.means_ = np.array([[0.0, 0.0], \n",
    "                             [5.0, 10.0]])\n",
    "    model.covars_ = np.tile(np.identity(2), (3, 1, 1))\n",
    "\n",
    "\n",
    "    #SAMPLING FROM MODEL and STORING IN TENSOR\n",
    "\n",
    "    #Number of Samples in Dataset\n",
    "    dataset=[]\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        X, Z = model.sample(length)\n",
    "        dataset.append(torch.Tensor(Z))\n",
    "\n",
    "    dataset = torch.stack(dataset)\n",
    "    \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "quarterly-potential",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = generate_hmm(2,10,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "fuzzy-newspaper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 100, 1])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-cornwall",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "closing-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Z = model.sample(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "devoted-creator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "applicable-thickness",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Injecting Noise into Labels\n",
    "\n",
    "#Given a flip_mask, flip an input\n",
    "def flip(array, flip_mask):\n",
    "    flipped_array = np.logical_xor(array, flip_mask)\n",
    "    return array, flipped_array\n",
    "\n",
    "#Class Independent / Time Independent\n",
    "def flip_labels_basic(array, flip_probability):\n",
    "    flip_mask = np.random.binomial(1, 0.5, len(array))\n",
    "    return flip(array, flip_mask)\n",
    "\n",
    "#Class Dependent / Time Independent\n",
    "def flip_labels_class(array, flip_probability_0, flip_probability_1):\n",
    "    flip_mask = []\n",
    "    for elem in array:\n",
    "        if elem == 0:\n",
    "            to_flip = np.random.binomial(1, flip_probability_0, 1)[0]\n",
    "            flip_mask.append(to_flip)\n",
    "        else:\n",
    "            to_flip = np.random.binomial(1, flip_probability_1, 1)[0]\n",
    "            flip_mask.append(to_flip)\n",
    "            \n",
    "    return flip(array, flip_mask)\n",
    "\n",
    "#Class Independent / Time Dependent\n",
    "def flip_labels_time(array, startprob, transmat):\n",
    "    flip_mask = generate_time_dependent_flip(1, len(array), startprob, transmat)[0]\n",
    "\n",
    "    return flip(array, flip_mask)\n",
    "\n",
    "\n",
    "#Class Dependent / Time Dependent\n",
    "#This can be achieved by careful design of the transition matrix (transmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "competent-shareware",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "        0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0]),\n",
       " tensor([1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "         1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "         0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "         0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "         0, 0, 1, 0], dtype=torch.uint8))"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startprob = random_startprob(2)\n",
    "transmat = np.array([[0.95, 0.05],\n",
    "                    [0.95, 0.05]])\n",
    "\n",
    "flip_labels_time(Z, startprob, transmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "junior-velvet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-dryer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-template",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stress Recov(3.6)",
   "language": "python",
   "name": "myenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
